# Dataset Information

These datasets were generated by the author of this project by scraping webpages of an online database that contains the moves of professional chess tournaments.

This directory contains:
* ```moves_raw.csv``` - the raw unprocessed data extracted from the webpages. Each entry represents a single tournament as a string.
* ```tokenised_moves.parquet``` - contains the processed data, with each key replaced with a unique string which represents a single unique token in the Llama tokenizer.
* ```tokenized_moves.json``` - a copy of ```tokenised_moves.parquet``` which can be previewed within the Github webpage

